# -*- coding: utf-8 -*-
"""EarthCam_Project_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rNQYMm2jBj8LbaRNjvChL0JwT-469m4o

# EarthCam Construction Site Intelligence Project

**Role:** Junior Data Scientist Candidate
**Goal:** Build an end-to-end computer vision pipeline to categorize site activity into 'Safety', 'Productivity', and 'Security' pillars.

---

## Phase 1: Environment Setup & Data Preparation
"""

# Install the Ultralytics package (YOLOv8)
!pip install ultralytics

import cv2
import pandas as pd
import sqlite3
import os
from ultralytics import YOLO
from datetime import datetime
import matplotlib.pyplot as plt
from IPython.display import Image, display

print("Setup complete. Libraries loaded.")

# Define the Business Pillars for aggregating detection data
# This dictionary maps the granular classes to executive-level categories.
CLASS_MAPPING = {
    # Safety Pillar (PPE Compliance)
    'Hardhat': 'Safety',
    'Mask': 'Safety',
    'NO-Hardhat': 'Safety',
    'NO-Mask': 'Safety',
    'NO-Safety Vest': 'Safety',
    'Person': 'Safety',
    'Safety Cone': 'Safety',
    'Safety Vest': 'Safety',

    # Productivity Pillar (Heavy Machinery & Active Work)
    'Excavator': 'Productivity',
    'Dump Truck': 'Productivity',
    'concrete mixer truck': 'Productivity',
    'grader': 'Productivity',
    'loader': 'Productivity',
    'truck': 'Productivity',
    'wheel loader': 'Productivity',

    # Security & Logistics (Site Access & Assets)
    'Bus': 'Security/Logistics',
    'Minivan': 'Security/Logistics',
    'SUV': 'Security/Logistics',
    'Sedan': 'Security/Logistics',
    'Trailer': 'Security/Logistics',
    'Van': 'Security/Logistics',
    'Vehicle': 'Security/Logistics',
    'machinery': 'Security/Logistics',

    # catch-all
    'fire hydrant': 'Security/Logistics'
}

# Helper function to get pillar from class name
def get_business_pillar(class_name):
    return CLASS_MAPPING.get(class_name, 'Uncategorized')

print("Business Pillars and Mapping Logic defined.")

"""## Phase 2: Model Training (YOLOv8-Nano)"""

model = YOLO('yolov8n.pt')

data_yaml_path = '/content/drive/MyDrive/Construction Site Safety.v1i.yolov8/data.yaml'
print(f"Training from Drive: {data_yaml_path}")

results = model.train(
    data=data_yaml_path,
    epochs=50,
    imgsz=640,
    project='/content/drive/MyDrive/earthcam-runs',  # Save here
    name='v1',
    plots=True
)
print("‚úÖ Training done‚Äîcheck Drive!")

import yaml
data_yaml_path = '/content/drive/MyDrive/Construction Site Safety.v1i.yolov8/data.yaml'

with open(data_yaml_path, 'r') as f:
    data = yaml.safe_load(f)

print("=== EarthCam Dataset Info ===")
print(f"Train path: {data['train']}")
print(f"Val path: {data['val']}")
print(f"Test path: {data.get('test', 'None')}")
print(f"Num classes: {data['nc']}")

print("\nClasses (25 total):")
classes = data['names'] if isinstance(data['names'], list) else list(data['names'].values())
for i, cls in enumerate(classes):
    print(f"  {i}: '{cls}'")

# All splits
base_dir = os.path.dirname(data_yaml_path)
train_imgs = len([f for f in os.listdir(f"{base_dir}/train/images") if f.endswith(('.jpg', '.png'))])
val_imgs = len([f for f in os.listdir(f"{base_dir}/valid/images") if f.endswith(('.jpg', '.png'))])
test_imgs = len([f for f in os.listdir(f"{base_dir}/test/images") if f.endswith(('.jpg', '.png'))]) if os.path.exists(f"{base_dir}/test/images") else 0

print(f"\nImages: train={train_imgs}, val={val_imgs}, test={test_imgs}")

print("\n‚úÖ Ready!")

# Drive paths (matches your project arg)
confusion_matrix_path = '/content/drive/MyDrive/earthcam-runs/v1/confusion_matrix.png'
results_path = '/content/drive/MyDrive/earthcam-runs/v1/results.png'

try:
    print("Model Performance - Confusion Matrix:")
    display(Image(filename=confusion_matrix_path))

    print("\nTraining Metrics:")
    display(Image(filename=results_path))
except Exception as e:
    print(f"Plots generating... Check Drive: {e}")
    !ls -la /content/drive/MyDrive/earthcam-runs/v1/

"""## Phase 3: Inference Engine & Analytics Generation"""

# === PHASE 3: INFERENCE ENGINE & ANALYTICS (DRIVE EDITION) ===

# 1. SETUP PATHS
# Upload a video to Drive and update name here!
video_path = '//YTDowncom_YouTube_SiteCloud-AERIAL-Drone-Photography-and-V_Media_IVspDj02u8U_001_1080p.mp4'

# Your 50-epoch model (saved in Drive from Phase 2)
best_weights = '/content/drive/MyDrive/earthcam-runs/v1/weights/best.pt'

# 2. LOAD MODEL
if not os.path.exists(best_weights):
    print(f"‚ö†Ô∏è Warning: Weights not found at {best_weights}")
    print("Using standard yolov8n.pt (demo mode). Check your Drive path!")
    best_model = YOLO('yolov8n.pt')
else:
    print(f"‚úÖ Loading custom EarthCam model: {best_weights}")
    best_model = YOLO(best_weights)

# 3. RUN INFERENCE
print(f"Processing video: {video_path}...")
analytics_data = []

# stream=True is efficient for long videos
# save=True saves the annotated video to 'runs/detect/predict'
results = best_model.predict(source=video_path, stream=True, save=True, conf=0.4)

frame_count = 0

# 4. PROCESS FRAMES
for frame in results:
    frame_count += 1

    # Get detected class IDs and Names
    class_indices = frame.boxes.cls.tolist()
    class_names = [best_model.names[int(idx)] for idx in class_indices]

    # Initialize counters for this frame
    frame_metrics = {
        'Safety': 0,
        'Productivity': 0,
        'Security/Logistics': 0,
        'Uncategorized': 0
    }

    # Map detections to Business Pillars (Safety, Productivity, etc.)
    # Assumes get_business_pillar() is defined from Phase 1
    for name in class_names:
        pillar = get_business_pillar(name)
        frame_metrics[pillar] += 1

    # Create structured record
    record = {
        'frame_id': frame_count,
        # Simulate time passing (30 FPS assumption for timestamp)
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'total_detections': len(class_names),
        **frame_metrics
    }
    analytics_data.append(record)

    if frame_count % 50 == 0:
        print(f"Processed frame {frame_count}...")

print(f"‚úÖ Video processing complete. Processed {frame_count} frames.")

# 5. CREATE DATAFRAME
df = pd.DataFrame(analytics_data)
print("\n=== Analytics Preview ===")
print(df.head())

# Save inferred video to Drive for easy viewing
# YOLO saves to runs/detect/predict/, let's copy it to Drive
import shutil
source_video_dir = 'runs/detect/predict'
if os.path.exists(source_video_dir):
    dest_dir = '/content/drive/MyDrive/earthcam-inference'
    shutil.copytree(source_video_dir, dest_dir, dirs_exist_ok=True)
    print(f"üé• Annotated video saved to Drive folder: {dest_dir}")

df = pd.DataFrame(analytics_data)
print(df.head())

import glob
from IPython.display import Video

# 1. Glob finds the latest AVI (no copy-paste needed)
latest_avi = glob.glob('/content/drive/MyDrive/earthcam-inference/*.avi')[0]

# 2. Convert & Play
!ffmpeg -i "$latest_avi" -vcodec libx264 "play_me.mp4" -y -loglevel quiet
Video("play_me.mp4", embed=True)

"""## Phase 4: SQL Pipeline & Export"""

# 1. CSV
csv_filename = 'final_site_report.csv'
df.to_csv(csv_filename, index=False)
print(f"CSV exported: {csv_filename}")

# 2. SQL Pipeline
db_name = 'earthcam_analytics.db'
conn = sqlite3.connect(db_name)
cursor = conn.cursor()

# Create table
cursor.execute('''
CREATE TABLE IF NOT EXISTS site_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    frame_id INTEGER,
    timestamp TEXT,
    total_detections INTEGER,
    safety_count INTEGER,
    productivity_count INTEGER,
    security_count INTEGER
);
''')

# Insert Data
for _, row in df.iterrows():
    cursor.execute('''
        INSERT INTO site_logs (frame_id, timestamp, total_detections, safety_count, productivity_count, security_count)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (
        row['frame_id'],
        row['timestamp'],
        row['total_detections'],
        row['Safety'],
        row['Productivity'],
        row['Security/Logistics']
    ))

conn.commit()
conn.close()

print(f"Database populated: {db_name}")